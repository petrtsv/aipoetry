{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:06:25.177239Z",
     "start_time": "2021-05-05T16:06:25.162237Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'markovify'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c7426ffa57db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmarkovify\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'markovify'"
     ]
    }
   ],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('poetry_dataset.txt', encoding='utf-8') as f:\n",
    "    read_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = markovify.NewlineText(read_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет Мир\n"
     ]
    }
   ],
   "source": [
    "text_te_bot = (i for i in input().split()) #text from telegram bot\n",
    "text_model.state_size = text_te_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:06:21.926492Z",
     "start_time": "2021-05-05T16:06:21.503210Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-acac0e680eb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'$'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(text_model.make_sentence().replace('$','\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NewlineText in module markovify.text:\n",
      "\n",
      "class NewlineText(Text)\n",
      " |  NewlineText(input_text, state_size=2, chain=None, parsed_sentences=None, retain_original=True, well_formed=True, reject_reg='')\n",
      " |  \n",
      " |  A (usable) example of subclassing markovify.Text. This one lets you markovify\n",
      " |  text where the sentences are separated by newlines instead of \". \"\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NewlineText\n",
      " |      Text\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  sentence_split(self, text)\n",
      " |      Splits full-text string into a list of sentences.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Text:\n",
      " |  \n",
      " |  __init__(self, input_text, state_size=2, chain=None, parsed_sentences=None, retain_original=True, well_formed=True, reject_reg='')\n",
      " |      input_text: A string.\n",
      " |      state_size: An integer, indicating the number of words in the model's state.\n",
      " |      chain: A trained markovify.Chain instance for this text, if pre-processed.\n",
      " |      parsed_sentences: A list of lists, where each outer list is a \"run\"\n",
      " |            of the process (e.g. a single sentence), and each inner list\n",
      " |            contains the steps (e.g. words) in the run. If you want to simulate\n",
      " |            an infinite process, you can come very close by passing just one, very\n",
      " |            long run.\n",
      " |      retain_original: Indicates whether to keep the original corpus.\n",
      " |      well_formed: Indicates whether sentences should be well-formed, preventing\n",
      " |            unmatched quotes, parenthesis by default, or a custom regular expression\n",
      " |            can be provided.\n",
      " |      reject_reg: If well_formed is True, this can be provided to override the\n",
      " |            standard rejection pattern.\n",
      " |  \n",
      " |  compile(self, inplace=False)\n",
      " |  \n",
      " |  generate_corpus(self, text)\n",
      " |      Given a text string, returns a list of lists; that is, a list of\n",
      " |      \"sentences,\" each of which is a list of words. Before splitting into\n",
      " |      words, the sentences are filtered through `self.test_sentence_input`\n",
      " |  \n",
      " |  make_sentence(self, init_state=None, **kwargs)\n",
      " |      Attempts `tries` (default: 10) times to generate a valid sentence,\n",
      " |      based on the model and `test_sentence_output`. Passes `max_overlap_ratio`\n",
      " |      and `max_overlap_total` to `test_sentence_output`.\n",
      " |      \n",
      " |      If successful, returns the sentence as a string. If not, returns None.\n",
      " |      \n",
      " |      If `init_state` (a tuple of `self.chain.state_size` words) is not specified,\n",
      " |      this method chooses a sentence-start at random, in accordance with\n",
      " |      the model.\n",
      " |      \n",
      " |      If `test_output` is set as False then the `test_sentence_output` check\n",
      " |      will be skipped.\n",
      " |      \n",
      " |      If `max_words` or `min_words` are specified, the word count for the sentence will be\n",
      " |      evaluated against the provided limit(s).\n",
      " |  \n",
      " |  make_sentence_with_start(self, beginning, strict=True, **kwargs)\n",
      " |      Tries making a sentence that begins with `beginning` string,\n",
      " |      which should be a string of one to `self.state` words known\n",
      " |      to exist in the corpus.\n",
      " |      \n",
      " |      If strict == True, then markovify will draw its initial inspiration\n",
      " |      only from sentences that start with the specified word/phrase.\n",
      " |      \n",
      " |      If strict == False, then markovify will draw its initial inspiration\n",
      " |      from any sentence containing the specified word/phrase.\n",
      " |      \n",
      " |      **kwargs are passed to `self.make_sentence`\n",
      " |  \n",
      " |  make_short_sentence(self, max_chars, min_chars=0, **kwargs)\n",
      " |      Tries making a sentence of no more than `max_chars` characters and optionally\n",
      " |      no less than `min_chars` characters, passing **kwargs to `self.make_sentence`.\n",
      " |  \n",
      " |  sentence_join(self, sentences)\n",
      " |      Re-joins a list of sentences into the full text.\n",
      " |  \n",
      " |  test_sentence_input(self, sentence)\n",
      " |      A basic sentence filter. The default rejects sentences that contain\n",
      " |      the type of punctuation that would look strange on its own\n",
      " |      in a randomly-generated sentence.\n",
      " |  \n",
      " |  test_sentence_output(self, words, max_overlap_ratio, max_overlap_total)\n",
      " |      Given a generated list of words, accept or reject it. This one rejects\n",
      " |      sentences that too closely match the original text, namely those that\n",
      " |      contain any identical sequence of words of X length, where X is the\n",
      " |      smaller number of (a) `max_overlap_ratio` (default: 0.7) of the total\n",
      " |      number of words, and (b) `max_overlap_total` (default: 15).\n",
      " |  \n",
      " |  to_dict(self)\n",
      " |      Returns the underlying data as a Python dict.\n",
      " |  \n",
      " |  to_json(self)\n",
      " |      Returns the underlying data as a JSON string.\n",
      " |  \n",
      " |  word_join(self, words)\n",
      " |      Re-joins a list of words into a sentence.\n",
      " |  \n",
      " |  word_split(self, sentence)\n",
      " |      Splits a sentence into a list of words.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from Text:\n",
      " |  \n",
      " |  from_chain(chain_json, corpus=None, parsed_sentences=None) from builtins.type\n",
      " |      Init a Text class based on an existing chain JSON string or object\n",
      " |      If corpus is None, overlap checking won't work.\n",
      " |  \n",
      " |  from_dict(obj, **kwargs) from builtins.type\n",
      " |  \n",
      " |  from_json(json_str) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Text:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from Text:\n",
      " |  \n",
      " |  reject_pat = re.compile('(^\\')|(\\'$)|\\\\s\\'|\\'\\\\s|[\\\\\"(\\\\(\\\\)\\\\[\\\\])]')\n",
      " |  \n",
      " |  word_split_pattern = re.compile('\\\\s+')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(markovify.NewlineText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
